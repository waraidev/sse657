{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_depot(url,hdepot,response='Other'):  \n",
    "    headers = {\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:66.0) Gecko/20100101 Firefox/66.0\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
    "\n",
    "    r = requests.get(str(url)+str(hdepot), headers=headers)\n",
    "    content = r.content\n",
    "    soup = BeautifulSoup(content)\n",
    "    \n",
    "    manufacturer = []\n",
    "    prices = []\n",
    "    describer = []\n",
    "    responder = []\n",
    "\n",
    "    items = soup.find_all('div', {'class':'package-pod__details-container  col__12-12'})\n",
    "    for item in items:\n",
    "        manufacturer.append(item.find('div', {'class': \"pod-description\"}).text.strip('\\n').strip(' ').strip('\\n'))\n",
    "        for price in item.find_all('div', {'class': 'price'}):\n",
    "            prices.append(''.join([price.strong.text.strip(), price.sup.text.strip()]))\n",
    "        for describe in item.find_all('div', {'class': 'grid'}):\n",
    "            describer.append(''.join([describe.strong.text.strip(), describe.sup.text.strip()]))\n",
    "        for resp in item:\n",
    "            responder = response\n",
    "            \n",
    "    \n",
    "    \n",
    "    items_info = zip(manufacturer,prices,describer,responder)\n",
    "    return items_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = 'https://www.homedepot.com/p/sets/powertools/package/'\n",
    "home_depot = ['Milwaukee/package_4','Dewalt/package_2','Ryobi/package_7','Rigid/package_11','Makita/package_14']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(home_depot)\n",
    "csv_results = []\n",
    "for i in range(n):\n",
    "    csv_results.append(get_depot(url1, home_depot[i],'Tool'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nordstrom(url,nord,response='Other'):  \n",
    "    headers = {\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:66.0) Gecko/20100101 Firefox/66.0\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
    "\n",
    "    r = requests.get(str(url)+str(nord), headers=headers)\n",
    "    content = r.content\n",
    "    soup = BeautifulSoup(content)\n",
    "    \n",
    "    manufacturer = []\n",
    "    prices = []\n",
    "    describer = []\n",
    "    responder = []\n",
    "\n",
    "    items = soup.find_all('article', {'class':'_1AOd3 QIjwE'})\n",
    "    for item in items:\n",
    "        manufacturer.append(item.find('div', {'class': \"pod-description\"}).text.strip('\\n').strip(' ').strip('\\n'))\n",
    "        for price in item.find_all('div', {'class': 'YbtDD _18N5Q'}):\n",
    "            prices.append(''.join([price.strong.text.strip(), price.sup.text.strip()]))\n",
    "        for describe in item.find_all('h3', {'class': 'Dawzg _28b4r'}):\n",
    "            describer.append(''.join([describe.strong.text.strip(), describe.sup.text.strip()]))\n",
    "        for resp in item:\n",
    "            responder = response\n",
    "            \n",
    "    \n",
    "    \n",
    "    items_info = zip(manufacturer,prices,describer,responder)\n",
    "    return items_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url2 = 'https://www.nordstrom.com/browse/women/clothing/'\n",
    "nordstrom = ['dresses?breadcrumb=Home%2FWomen%2FClothing%2FDresses&origin=topnav','jeans?breadcrumb=Home%2FWomen%2FClothing%2FJeans%20%26%20Denim&origin=topnav']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(nordstrom)\n",
    "for i in range(n):\n",
    "    csv_results.append(get_data(url2, nordstrom[i],'Fashion'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "df = pd.DataFrame(flatten(csv_results),columns=['Manufacturer','Price','Description','Class'])\n",
    "df.to_csv('products.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('products.csv', index_col = 0)\n",
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(str(0), np.nan, inplace=True)\n",
    "df.replace(0, np.nan, inplace=True)\n",
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df, train_size = 0.7, random_state =42)\n",
    "\n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_test = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'Class ~ Manufacturer+Price+Description'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.glm(formula = formula, data = x_train, family = sm.families.Binomial())\n",
    "result = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = result.predict(x_test)\n",
    "predictions_nominal = [\"Tool\" if x < 0.5 else \"Fashion\" for x in predictions]\n",
    "print(classification_report(y_test, predictions_nominal, digits = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors = 3)\n",
    "pred = knn.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, pred).T)\n",
    "print(classification_report(y_test, pred, digits=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
